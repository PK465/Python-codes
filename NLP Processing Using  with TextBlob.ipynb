{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "string1=TextBlob(\"Pratap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string2=TextBlob(\"Kumar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"rata\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"PRATAP\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"PRATAP  KUMAR\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.upper() +\"  \"+ string2.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP TASKS USING TEXT BLOB\n",
    "#1.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization refers to divided text or a sentence into a sequence of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text=TextBlob(\"India is a popular tourist destination with its history, architecture and geographical splendor.\\n There are several languages spoken all over India.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, this textblob can be tokenized into a sentence and further into words. Let’s look at the code shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"India is a popular tourist destination with its history, architecture and geographical splendor.\"),\n",
       " Sentence(\"There are several languages spoken all over India.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1=Text.sentences[0]  ## extracting only first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'is', 'a', 'popular', 'tourist', 'destination', 'with', 'its', 'history', 'architecture', 'and', 'geographical', 'splendor']\n"
     ]
    }
   ],
   "source": [
    "## printing words of second sentence in single line format\n",
    "\n",
    "print(Text.sentences[0].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There\n",
      "are\n",
      "several\n",
      "languages\n",
      "spoken\n",
      "all\n",
      "over\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "for words in Text.sentences[1].words:  ## printing words of second sentence line by line\n",
    " print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india\n",
      "popular tourist destination\n",
      "geographical splendor\n"
     ]
    }
   ],
   "source": [
    "2.#Noun Phrase Extraction\n",
    "\n",
    "for np in Text.sentences[0].noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India NNP\n",
      "is VBZ\n",
      "a DT\n",
      "popular JJ\n",
      "tourist NN\n",
      "destination NN\n",
      "with IN\n",
      "its PRP$\n",
      "history NN\n",
      "architecture NN\n",
      "and CC\n",
      "geographical JJ\n",
      "splendor NN\n"
     ]
    }
   ],
   "source": [
    "#3 Part-of-speech Tagging\n",
    "#Part-of-speech tagging or grammatical tagging is a method to mark words present in a text on the basis of its definition and context. In simple words, it tells whether a word is a noun, or an adjective, or a verb, etc. This is just a complete version of noun phrase extraction, where we want to find all the the parts of speech in a sentence.\n",
    "for words, tag in Text.sentences[0].tags:\n",
    "    \n",
    "    print(words,tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here NNP is Noun,JJ is Adjective, IN  is Conjection etc.You can check the full list of tags from https://www.clips.uantwerpen.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languages\n",
      "language\n"
     ]
    }
   ],
   "source": [
    "#4 Words Inflection and Lemmatization\n",
    "#Inflection is a process of word formation in which characters are added to the base form of a word to express grammatical meanings. Word inflection in TextBlob is very simple, i.e., the words we tokenized from a textblob can be easily changed into singular or plural\n",
    "\n",
    "\n",
    "print(Text.sentences[1].words[3])\n",
    "print(Text.sentences[1].words[3].singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strings'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextBlob library also offers an in-build object known as Word. We just need to create a word object and then apply a function directly to it as shown below.\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "T1=Word(\"string\")\n",
    "T1.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tourists\n",
      "destinations\n",
      "histories\n",
      "architectures\n",
      "splendors\n"
     ]
    }
   ],
   "source": [
    "#using tags\n",
    "\n",
    "for words,pos in Text.sentences[0].tags:\n",
    "    if pos==\"NN\":\n",
    "        print(words.pluralize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Words can be lemmatized using the lemmatize function.\n",
    "## lemmatization\n",
    "w = Word('walking')\n",
    "w.lemmatize(\"v\") ## v here represents verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'is']\n",
      "['is', 'a']\n",
      "['a', 'popular']\n",
      "['popular', 'tourist']\n",
      "['tourist', 'destination']\n",
      "['destination', 'with']\n",
      "['with', 'its']\n",
      "['its', 'history']\n",
      "['history', 'architecture']\n",
      "['architecture', 'and']\n",
      "['and', 'geographical']\n",
      "['geographical', 'splendor']\n"
     ]
    }
   ],
   "source": [
    "#5 N-grams\n",
    "#A combination of multiple words together are called N-Grams. N grams (N > 1) are generally more informative as compared to words, and can be used as features for language modelling.  N-grams can be easily accessed in TextBlob using the ngrams function, which returns a tuple of n successive words.\n",
    "\n",
    "for ngram in Text.sentences[0].ngrams(2):\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Sentiment Analysis\n",
    "#Sentiment analysis is basically the process of determining the attitude or the emotion of the writer, i.e., whether it is positive or negative or neutral.\n",
    "\n",
    "#The sentiment function of textblob returns two properties, polarity, and subjectivity.\n",
    "\n",
    "#Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1].\n",
    "\n",
    "#Let’s check the sentiment of our Text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is a popular tourist destination with its history, architecture and geographical splendor.\n",
      "Sentiment(polarity=0.6, subjectivity=0.9)\n"
     ]
    }
   ],
   "source": [
    "print(Text.sentences[0])\n",
    "\n",
    "print(Text.sentences[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that polarity is 0.6, which means that the statement is positive and 0.9 subjectivity refers that mostly it is a public opinion and not a factual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"India is a popular tourist destination with its history\")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. Spelling Correction\n",
    "\n",
    "Text1=TextBlob(\"India is a poplar touist destinatin with its histary\")\n",
    "Text1.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('popular', 0.9925373134328358), ('polar', 0.007462686567164179)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also check the list of suggested word and its confidence using the spellcheck function.\n",
    "\n",
    "Text1.words[3].spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Translation and Language Detection\n",
    "Text=TextBlob(\" j'aime mon inde \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text.detect_language()  #It is French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"i like my india\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now translate that word into English\n",
    "\n",
    "Text.translate(from_lang='fr' ,to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"i like my india\")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text.translate(to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text classification using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s build a simple text classification model using TextBlob. For this, first, we need to prepare a training and testing data.\n",
    "\n",
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "      contains(terrible) = False             neg : pos    =      1.8 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Textblob provides in-build classifiers module to create a custom classifier. So, let’s quickly import it and create a basic classifier.\n",
    "\n",
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)\n",
    " \n",
    "\n",
    "#As you can see above, we have passed the training data into the classifier.\n",
    "\n",
    "#Note that here we have used Naive Bayes classifier, but TextBlob also offers Decision tree classifier which is as shown below.\n",
    "\n",
    "## decision tree classifier\n",
    "dt_classifier = classifiers.DecisionTreeClassifier(training)\n",
    "#Now, let’s check the accuracy of this classifier on the testing dataset and also TextBlob provides us to check the most informative features.\n",
    "\n",
    "print (classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, based on the training on the above dataset, our classifier has provided us the right result.\n",
    "\n",
    "#Note that here we could have done some preprocessing and data cleaning but here my aim was to give you an intuition that how we can do text classification using TextBlob.\n",
    "\n",
    "#Pros and Cons\n",
    "#Pros:\n",
    "#Since, it is built on the shoulders of NLTK and Pattern, therefore making it simple for beginners by providing an intuitive interface to NLTK.\n",
    "#It provides language translation and detection which is powered by Google Translate ( not provided with Spacy).\n",
    "#Cons:\n",
    "#It is little slower in the comparison to spacy but faster than NLTK. (Spacy > TextBlob > NLTK)\n",
    "#It does not provide features like dependency parsing, word vectors etc. which is provided by spacy.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Notes\n",
    "#I hope that you that a fun time learning about this library. TextBlob, actually provided a very easy interface for beginners to learn basic NLP tasks.\n",
    "\n",
    "#I would recommend every beginner to start with this library and then in order to do advance work you can learn spacy as well. We will still be using TextBlob for initial prototyping in the almost every NLP project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
